{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "\n",
    "X_train = pd.read_csv('./train_with_prob.csv', index_col=False)\n",
    "X_train = X_train.drop('Unnamed: 0', axis=1)\n",
    "X_train.head()\n",
    "\n",
    "y_train = df_train['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train['q1_q2_freq_diff'] = np.abs(X_train['q1_freq'] - X_train['q2_freq'])\n",
    "X_train['q1_q2_freq_sum'] = X_train['q1_freq'] + X_train['q2_freq']\n",
    "X_train['skew_diff'] = np.abs(X_train['skew_q1vec'] - X_train['skew_q2vec'])\n",
    "X_train['skew_sum'] = X_train['skew_q1vec'] + X_train['skew_q2vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train = X_train.drop('skew_q1vec', axis=1)\n",
    "# X_train = X_train.drop('skew_q2vec', axis=1)\n",
    "# X_train = X_train.drop('q1_freq', axis=1)\n",
    "# X_train = X_train.drop('q2_freq', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Up/down sampling\n",
    "pos_train = X_train[y_train == 1]\n",
    "neg_train = X_train[y_train == 0]\n",
    "X_train = pd.concat((neg_train, pos_train.iloc[:int(0.8 * len(pos_train))],\n",
    "                     neg_train))\n",
    "y_train = np.array([0] * neg_train.shape[0] + [1] * pos_train.iloc[:int(\n",
    "    0.8 * len(pos_train))].shape[0] + [0] * neg_train.shape[0])\n",
    "print(np.mean(y_train))\n",
    "del pos_train, neg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_model(params, X_train, y_train):\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    clf = GridSearchCV(\n",
    "        xgb_model,\n",
    "        params,\n",
    "        n_jobs=5,\n",
    "        cv=5,\n",
    "        scoring='neg_log_loss',\n",
    "        verbose=2,\n",
    "        refit=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# brute force scan for all parameters, here are the tricks\n",
    "# usually max_depth is 6,7,8\n",
    "# learning rate is around 0.05, but small changes may make big diff\n",
    "# tuning min_child_weight subsample colsample_bytree can have\n",
    "# much fun of fighting against overfit\n",
    "# n_estimators is how many round of boosting\n",
    "# finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "params = [{\n",
    "    'objective': ['binary:logistic'],\n",
    "    'learning_rate': [0.0225],\n",
    "    'max_depth': [8],\n",
    "    'subsample': [0.7],\n",
    "    'colsample_bytree': [0.75],\n",
    "    'n_estimators': [300],\n",
    "    'base_score': [0.2],\n",
    "    'seed': [911]\n",
    "}]\n",
    "#     , {\n",
    "#     'objective': ['binary:logistic'],\n",
    "#     'learning_rate': [0.02],\n",
    "#     'max_depth': [8, 9],\n",
    "#     'subsample': [0.75],\n",
    "#     'colsample_bytree': [0.75, 0.7],\n",
    "#     'n_estimators': [500],\n",
    "#     'seed': [666]\n",
    "# }, {\n",
    "#     'objective': ['binary:logistic'],\n",
    "#     'learning_rate': [0.02],\n",
    "#     'max_depth': [8, 9],\n",
    "#     'subsample': [0.75],\n",
    "#     'colsample_bytree': [0.75, 0.7],\n",
    "#     'n_estimators': [500],\n",
    "#     'seed': [250]\n",
    "# }, {\n",
    "#     'objective': ['binary:logistic'],\n",
    "#     'learning_rate': [0.02],\n",
    "#     'max_depth': [8, 9],\n",
    "#     'subsample': [0.75],\n",
    "#     'colsample_bytree': [0.75, 0.7],\n",
    "#     'n_estimators': [250],\n",
    "#     'seed': [250]\n",
    "# }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_match</th>\n",
       "      <th>tfidf_wm</th>\n",
       "      <th>tfidf_wm_stops</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>wc_diff</th>\n",
       "      <th>wc_ratio</th>\n",
       "      <th>wc_diff_unique</th>\n",
       "      <th>wc_ratio_unique</th>\n",
       "      <th>wc_diff_unq_stop</th>\n",
       "      <th>wc_ratio_unique_stop</th>\n",
       "      <th>...</th>\n",
       "      <th>clf_127</th>\n",
       "      <th>clf_128</th>\n",
       "      <th>clf_129</th>\n",
       "      <th>clf_130</th>\n",
       "      <th>clf_131</th>\n",
       "      <th>clf_132</th>\n",
       "      <th>q1_q2_freq_diff</th>\n",
       "      <th>q1_q2_freq_sum</th>\n",
       "      <th>skew_diff</th>\n",
       "      <th>skew_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.234251</td>\n",
       "      <td>0.274019</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>3</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>2</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>3</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>0.055948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.436043</td>\n",
       "      <td>0.480962</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>0.302897</td>\n",
       "      <td>0.301840</td>\n",
       "      <td>0.447476</td>\n",
       "      <td>0.394525</td>\n",
       "      <td>0.442324</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>-0.064240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.418727</td>\n",
       "      <td>0.468893</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>8</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>6</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385672</td>\n",
       "      <td>0.449783</td>\n",
       "      <td>0.421432</td>\n",
       "      <td>0.427320</td>\n",
       "      <td>0.394525</td>\n",
       "      <td>0.442324</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.131041</td>\n",
       "      <td>0.014628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.130016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.841273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390569</td>\n",
       "      <td>0.494767</td>\n",
       "      <td>0.530017</td>\n",
       "      <td>0.416894</td>\n",
       "      <td>0.426159</td>\n",
       "      <td>0.492876</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_match  tfidf_wm  tfidf_wm_stops   jaccard  wc_diff  wc_ratio  \\\n",
       "0    0.266667  0.234251        0.274019  0.090909        3  1.272727   \n",
       "1    0.500000  0.436043        0.480962  0.235294        7  0.500000   \n",
       "2    0.444444  0.418727        0.468893  0.285714        8  0.428571   \n",
       "3    0.000000  0.000000        0.000000  0.000000        1  0.750000   \n",
       "4    0.800000  0.841273        1.000000  0.428571        2  1.500000   \n",
       "\n",
       "   wc_diff_unique  wc_ratio_unique  wc_diff_unq_stop  wc_ratio_unique_stop  \\\n",
       "0               2         1.181818                 3              1.500000   \n",
       "1               7         0.500000                 2              0.714286   \n",
       "2               6         0.500000                 3              0.500000   \n",
       "3               1         0.750000                 0              1.000000   \n",
       "4               2         1.500000                 1              0.666667   \n",
       "\n",
       "     ...      clf_127   clf_128   clf_129   clf_130   clf_131   clf_132  \\\n",
       "0    ...     0.000100  0.006660  0.000000  0.001944  0.002864  0.000000   \n",
       "1    ...     0.296028  0.302897  0.301840  0.447476  0.394525  0.442324   \n",
       "2    ...     0.385672  0.449783  0.421432  0.427320  0.394525  0.442324   \n",
       "3    ...     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4    ...     0.390569  0.494767  0.530017  0.416894  0.426159  0.492876   \n",
       "\n",
       "   q1_q2_freq_diff  q1_q2_freq_sum  skew_diff  skew_sum  \n",
       "0                0               2   0.036032  0.055948  \n",
       "1                0               4   0.029401 -0.064240  \n",
       "2                0               2   0.131041  0.014628  \n",
       "3                0               2   0.009182  0.130016  \n",
       "4                0               2   0.000000  0.012170  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./data/test.csv')\n",
    "X_test = pd.read_csv('./test_with_prob.csv')\n",
    "X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "X_test['q1_q2_freq_diff'] = np.abs(X_test['q1_freq'] - X_test['q2_freq'])\n",
    "X_test['q1_q2_freq_sum'] = X_test['q1_freq'] + X_test['q2_freq']\n",
    "X_test['skew_diff'] = np.abs(X_test['skew_q1vec'] - X_test['skew_q2vec'])\n",
    "X_test['skew_sum'] = X_test['skew_q1vec'] + X_test['skew_q2vec']\n",
    "\n",
    "# X_test = X_test.drop('skew_q1vec', axis=1)\n",
    "# X_test = X_test.drop('skew_q2vec', axis=1)\n",
    "# X_test = X_test.drop('q1_freq', axis=1)\n",
    "# X_test = X_test.drop('q2_freq', axis=1)\n",
    "\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = df_test['test_id']\n",
    "\n",
    "for p in params:\n",
    "    clf = select_model(p, X_train, y_train)\n",
    "    print(idx, ':', clf.best_estimator_, '\\n\\n\\n')\n",
    "    best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "    print(best_parameters, score)\n",
    "    test_probs = clf.predict_proba(X_test)\n",
    "    sub['is_duplicate_{}'.format(idx)] = test_probs[:, 1]\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # sub = pd.DataFrame()\n",
    "# # sub['test_id'] = df_test['test_id']\n",
    "sub['is_duplicate'] = sub['is_duplicate_0']\n",
    "sub = sub[['test_id', 'is_duplicate']]\n",
    "print('\\nPrediction result:\\n',sub.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Saving :: submission file...')\n",
    "sub.to_csv('sub_11-30.csv', index=False)\n",
    "print('\\nSubmission result done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
