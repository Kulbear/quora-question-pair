{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train = np.load(\"_train.npy\")\n",
    "assert features_train.shape == (404290, 25), \"Something wrong with the train features...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_test = np.load(\"_test.npy\")\n",
    "assert features_test.shape == (2345796, 25), \"Something wrong with the test features...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw datasets...\n",
      "Loaded.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading raw datasets...\")\n",
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "print(\"Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = features_train\n",
    "X_test = pd.DataFrame(features_test)\n",
    "y_train = train['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.189701079013\n"
     ]
    }
   ],
   "source": [
    "# Up/down sampling\n",
    "pos_train = pd.DataFrame(X_train[y_train == 1])\n",
    "neg_train = pd.DataFrame(X_train[y_train == 0])\n",
    "X_train = pd.concat((neg_train, pos_train.iloc[:int(0.8 * len(pos_train))],\n",
    "                     neg_train))\n",
    "y_train = np.array([0] * neg_train.shape[0] + [1] * pos_train.iloc[:int(\n",
    "    0.8 * len(pos_train))].shape[0] + [0] * neg_train.shape[0])\n",
    "print(np.mean(y_train))\n",
    "del pos_train, neg_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_model(params, X_train, y_train):\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "    clf = GridSearchCV(\n",
    "        xgb_model,\n",
    "        params,\n",
    "        n_jobs=5,\n",
    "        cv=5, # This number should be modified to 10, 5 is just for demo\n",
    "        scoring='neg_log_loss',\n",
    "        verbose=2,\n",
    "        refit=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# brute force scan for all parameters, here are the tricks\n",
    "# usually max_depth is 6,7,8\n",
    "# learning rate is around 0.05, but small changes may make big diff\n",
    "# tuning min_child_weight subsample colsample_bytree can have\n",
    "# much fun of fighting against overfit\n",
    "# n_estimators is how many round of boosting\n",
    "# finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "# the advice above from a Kagglers kernal, failed to find the link again\n",
    "\n",
    "# Just for demo, should actually have a lot of parameter combinations\n",
    "params = [{\n",
    "    'objective': ['binary:logistic'],\n",
    "    'learning_rate': [0.0225],\n",
    "    'max_depth': [8],\n",
    "    'subsample': [0.7],\n",
    "    'colsample_bytree': [0.75],\n",
    "    'n_estimators': [300],\n",
    "    'base_score': [0.2],\n",
    "    'seed': [911]\n",
    "}]\n",
    "#     , {\n",
    "#     'objective': ['binary:logistic'],\n",
    "#     'learning_rate': [0.02],\n",
    "#     'max_depth': [8, 9],\n",
    "#     'subsample': [0.8],\n",
    "#     'colsample_bytree': [0.75, 0.7],\n",
    "#     'n_estimators': [200],\n",
    "#     'seed': [666]\n",
    "# }, {\n",
    "#     'objective': ['binary:logistic'],\n",
    "#     'learning_rate': [0.02],\n",
    "#     'max_depth': [8, 9],\n",
    "#     'subsample': [0.75],\n",
    "#     'colsample_bytree': [0.75, 0.7],\n",
    "#     'n_estimators': [300],\n",
    "#     'seed': [250]\n",
    "# }, {\n",
    "#     'objective': ['binary:logistic'],\n",
    "#     'learning_rate': [0.02],\n",
    "#     'max_depth': [8, 9],\n",
    "#     'subsample': [0.7],\n",
    "#     'colsample_bytree': [0.75, 0.7],\n",
    "#     'n_estimators': [250],\n",
    "#     'seed': [250]\n",
    "# }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed: 13.3min remaining: 20.0min\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed: 13.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed: 13.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : XGBClassifier(base_score=0.2, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.75, gamma=0, learning_rate=0.0225,\n",
      "       max_delta_step=0, max_depth=8, min_child_weight=1, missing=None,\n",
      "       n_estimators=300, n_jobs=1, nthread=None,\n",
      "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=911, silent=True,\n",
      "       subsample=0.7) \n",
      "\n",
      "\n",
      "\n",
      "{'base_score': 0.2, 'colsample_bytree': 0.75, 'learning_rate': 0.0225, 'max_depth': 8, 'n_estimators': 300, 'objective': 'binary:logistic', 'seed': 911, 'subsample': 0.7} -0.19940911393075803\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = test['test_id']\n",
    "\n",
    "for p in params:\n",
    "    clf = select_model(p, X_train, y_train)\n",
    "    print(idx, ':', clf.best_estimator_, '\\n\\n\\n')\n",
    "    best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "    print(best_parameters, score)\n",
    "    test_probs = clf.predict_proba(X_test)\n",
    "    sub['is_duplicate_{}'.format(idx)] = test_probs[:, 1]\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>is_duplicate_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.110052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.297908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.159587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id  is_duplicate_0\n",
       "0        0        0.009606\n",
       "1        1        0.110052\n",
       "2        2        0.297908\n",
       "3        3        0.000505\n",
       "4        4        0.159587"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('Saving :: submission file...')\n",
    "# sub.to_csv('sub_11-30.csv', index=False)\n",
    "# print('\\nSubmission result done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
